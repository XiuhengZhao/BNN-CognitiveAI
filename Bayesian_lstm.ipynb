{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyeMtx0sdxHt",
        "outputId": "0291ba48-6219-4c79-b966-7add788d96d3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyro-ppl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYAtHZa4fKKM",
        "outputId": "f75d5a41-7fed-4447-e721-5284271cc833"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyro-ppl\n",
            "  Downloading pyro_ppl-1.9.0-py3-none-any.whl (745 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m745.2/745.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (3.3.0)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl) (4.66.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.0->pyro-ppl)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.0->pyro-ppl)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.0->pyro-ppl)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.0->pyro-ppl)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.0->pyro-ppl)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.0->pyro-ppl)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.0->pyro-ppl)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.0->pyro-ppl)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.0->pyro-ppl)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2.0->pyro-ppl)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.0->pyro-ppl)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pyro-ppl) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0->pyro-ppl)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->pyro-ppl) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0->pyro-ppl) (1.3.0)\n",
            "Installing collected packages: pyro-api, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pyro-ppl\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pyro-api-0.1.2 pyro-ppl-1.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AfCXF7U3c9QS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader, Dataset,random_split,SubsetRandomSampler, WeightedRandomSampler\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pyro\n",
        "import pyro.distributions as dist\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gp_3jRkZc9QX"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hrlUTSyZc9QX"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed=3407): # The torch.manual_seed(3407) is all you need! xD\n",
        "    \"\"\"\n",
        "    Seed everything to make all operations in PyTorch (and other libraries) deterministic.\n",
        "    Args:\n",
        "        seed (int): Seed value to set.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "seed_everything()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x-EajEJ1c9QY"
      },
      "outputs": [],
      "source": [
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_cont = torch.tensor(self.dataframe.iloc[idx]['X_cont'], dtype=torch.float32)\n",
        "\n",
        "        other_cols = self.dataframe.drop(columns=['label', 'X_cont','Unit1'])\n",
        "        x_other = torch.tensor(other_cols.iloc[idx].values, dtype=torch.float32)\n",
        "\n",
        "        label = torch.tensor(self.dataframe.iloc[idx]['label'], dtype=torch.long)\n",
        "\n",
        "        return x_cont, x_other, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Z_CTXJiIc9QZ"
      },
      "outputs": [],
      "source": [
        "class BayesianLSTM(nn.Module):\n",
        "    def __init__(self, dyn_channels=5, stat_channels=32, hidden_size=50, num_layers=2):\n",
        "        super(BayesianLSTM, self).__init__()\n",
        "        # lstm part\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(dyn_channels, hidden_size, num_layers, batch_first=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(hidden_size, 25)\n",
        "        self.fc2 = nn.Linear(25, 15)\n",
        "\n",
        "        # fc part\n",
        "        self.fc_static1 = nn.Linear(stat_channels,30)\n",
        "        self.fc_static2 = nn.Linear(30,15)\n",
        "\n",
        "        # fusion part\n",
        "        self.fc_final1 = nn.Linear(30,2)\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x_dynamic, x_static):\n",
        "        h0 = torch.zeros(self.num_layers, x_dynamic.size(0), self.hidden_size).to(x_dynamic.device)\n",
        "        c0 = torch.zeros(self.num_layers, x_dynamic.size(0), self.hidden_size).to(x_dynamic.device)\n",
        "        out1, _ = self.lstm(x_dynamic, (h0, c0))\n",
        "        out1 = self.relu(self.fc1(out1[:, -1, :]))\n",
        "        out1 = self.relu(self.fc2(out1))\n",
        "\n",
        "        out2 = self.relu(self.fc_static1(x_static))\n",
        "        out2 = self.relu(self.fc_static2(out2))\n",
        "\n",
        "        out = torch.cat((out1, out2), dim=1)\n",
        "        out = self.fc_final1(out)\n",
        "\n",
        "        return out\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = BayesianLSTM(dyn_channels=5, stat_channels=32, hidden_size=50, num_layers=2).to(device)\n",
        "log_softmax = nn.LogSoftmax(dim=1)\n",
        "def model(x_dynamic, x_static, y=None):\n",
        "        # Define prior distributions for all neural network weights\n",
        "        lstm_weightih0_prior = dist.Normal(loc=torch.zeros_like(net.lstm.weight_ih_l0).to(device), scale=5*torch.ones_like(net.lstm.weight_ih_l0).to(device)).to_event(2)\n",
        "        lstm_biasih0_prior = dist.Normal(loc=torch.zeros_like(net.lstm.bias_ih_l0).to(device), scale=5*torch.ones_like(net.lstm.bias_ih_l0).to(device)).to_event(1)\n",
        "        lstm_weightih1_prior = dist.Normal(loc=torch.zeros_like(net.lstm.weight_ih_l1).to(device), scale=5*torch.ones_like(net.lstm.weight_ih_l1).to(device)).to_event(2)\n",
        "        lstm_biasih1_prior = dist.Normal(loc=torch.zeros_like(net.lstm.bias_ih_l1).to(device), scale=5*torch.ones_like(net.lstm.bias_ih_l1).to(device)).to_event(1)\n",
        "        lstm_weighthh0_prior = dist.Normal(loc=torch.zeros_like(net.lstm.weight_hh_l0).to(device), scale=5*torch.ones_like(net.lstm.weight_hh_l0).to(device)).to_event(2)\n",
        "        lstm_biashh0_prior = dist.Normal(loc=torch.zeros_like(net.lstm.bias_hh_l0).to(device), scale=5*torch.ones_like(net.lstm.bias_hh_l0).to(device)).to_event(1)\n",
        "        lstm_weighthh1_prior = dist.Normal(loc=torch.zeros_like(net.lstm.weight_hh_l1).to(device), scale=5*torch.ones_like(net.lstm.weight_hh_l1).to(device)).to_event(2)\n",
        "        lstm_biashh1_prior = dist.Normal(loc=torch.zeros_like(net.lstm.bias_hh_l1).to(device), scale=5*torch.ones_like(net.lstm.bias_hh_l1).to(device)).to_event(1)\n",
        "        #lstm_weighthr0_prior = dist.Normal(loc=torch.zeros_like(self.lstm.weight_hr_l0), scale=torch.ones_like(self.lstm.weight_hr_l0))\n",
        "        #lstm_biashr0_prior = dist.Normal(loc=torch.zeros_like(self.lstm.bias_hr_l0), scale=torch.ones_like(self.lstm.bias_hr_l0))\n",
        "        #lstm_weighthr1_prior = dist.Normal(loc=torch.zeros_like(self.lstm.weight_hr_l1), scale=torch.ones_like(self.lstm.weight_hr_l1))\n",
        "        #lstm_biashr1_prior = dist.Normal(loc=torch.zeros_like(self.lstm.bias_hr_l1), scale=torch.ones_like(self.lstm.bias_hr_l1))\n",
        "        fc1w_prior = dist.Normal(loc=torch.zeros_like(net.fc1.weight).to(device), scale=5*torch.ones_like(net.fc1.weight).to(device)).to_event(2)\n",
        "        fc1b_prior = dist.Normal(loc=torch.zeros_like(net.fc1.bias).to(device), scale=5*torch.ones_like(net.fc1.bias).to(device)).to_event(1)\n",
        "        fc2w_prior = dist.Normal(loc=torch.zeros_like(net.fc2.weight).to(device), scale=5*torch.ones_like(net.fc2.weight).to(device)).to_event(2)\n",
        "        fc2b_prior = dist.Normal(loc=torch.zeros_like(net.fc2.bias).to(device), scale=5*torch.ones_like(net.fc2.bias).to(device)).to_event(1)\n",
        "        fc_static1w_prior = dist.Normal(loc=torch.zeros_like(net.fc_static1.weight).to(device), scale=5*torch.ones_like(net.fc_static1.weight).to(device)).to_event(2)\n",
        "        fc_static1b_prior = dist.Normal(loc=torch.zeros_like(net.fc_static1.bias).to(device), scale=5*torch.ones_like(net.fc_static1.bias).to(device)).to_event(1)\n",
        "        fc_static2w_prior = dist.Normal(loc=torch.zeros_like(net.fc_static2.weight).to(device), scale=5*torch.ones_like(net.fc_static2.weight).to(device)).to_event(2)\n",
        "        fc_static2b_prior = dist.Normal(loc=torch.zeros_like(net.fc_static2.bias).to(device), scale=5*torch.ones_like(net.fc_static2.bias).to(device)).to_event(1)\n",
        "        fc_final1w_prior = dist.Normal(loc=torch.zeros_like(net.fc_final1.weight).to(device), scale=5*torch.ones_like(net.fc_final1.weight).to(device)).to_event(2)\n",
        "        fc_final1b_prior = dist.Normal(loc=torch.zeros_like(net.fc_final1.bias).to(device), scale=5*torch.ones_like(net.fc_final1.bias).to(device)).to_event(1)\n",
        "\n",
        "\n",
        "        model_priors = {\n",
        "            'lstm.weight_ih_l0': lstm_weightih0_prior, 'lstm.bias_ih_l0': lstm_biasih0_prior,\n",
        "            'lstm.weight_ih_l1': lstm_weightih1_prior, 'lstm.bias_ih_l1': lstm_biasih1_prior,\n",
        "            'lstm.weight_hh_l0': lstm_weighthh0_prior, 'lstm.bias_hh_l0': lstm_biashh0_prior,\n",
        "            'lstm.weight_hh_l1': lstm_weighthh1_prior, 'lstm.bias_hh_l1': lstm_biashh1_prior,\n",
        "            #'lstm.weight_hr_l0': lstm_weighthr0_prior, 'lstm.bias_hr_l0': lstm_biashr0_prior,\n",
        "            #'lstm.weight_hr_l1': lstm_weighthr1_prior, 'lstm.bias_hr_l1': lstm_biashr1_prior,\n",
        "            'fc1.weight': fc1w_prior, 'fc1.bias': fc1b_prior,\n",
        "            'fc2.weight': fc2w_prior, 'fc2.bias': fc2b_prior,\n",
        "            'fc_static1.weight': fc_static1w_prior, 'fc_static1.bias': fc_static1b_prior,\n",
        "            'fc_static2.weight': fc_static2w_prior, 'fc_static2.bias': fc_static2b_prior,\n",
        "            #'fc_static3.weight': fc_static3w_prior, 'fc_static3.bias': fc_static3b_prior,\n",
        "            'fc_final1.weight': fc_final1w_prior, 'fc_final1.bias': fc_final1b_prior,\n",
        "            #'fc_final2.weight': fc_final2w_prior, 'fc_final2.bias': fc_final2b_prior\n",
        "        }\n",
        "        lifted_module = pyro.random_module(\"module\", net, model_priors)  # Lift module parameters to random variables\n",
        "        lifted_reg_model = lifted_module()\n",
        "        #with pyro.plate(\"data\", x_dynamic.size(0)):\n",
        "        lhat = log_softmax(lifted_reg_model(x_dynamic, x_static))\n",
        "        if y is not None:\n",
        "                y = y.float()\n",
        "        pyro.sample(\"obs\", dist.Categorical(logits=lhat).to_event(1), obs=y)\n",
        "        return lhat\n",
        "\n",
        "\n",
        "# Defining the guide function for variational inference\n",
        "softplus = torch.nn.Softplus()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "def guide(x_dynamic, x_static, y=None):\n",
        "        # Define variational distributions for the parameters (learnable)\n",
        "        #softplus = torch.nn.Softplus()\n",
        "        lstm_weightih0_mu = torch.randn_like(net.lstm.weight_ih_l0)\n",
        "        lstm_weightih0_sigma = torch.randn_like(net.lstm.weight_ih_l0)\n",
        "        lstm_weightih0_mu_param = pyro.param(\"lstm_weightih0_mu\", lstm_weightih0_mu).to(device)\n",
        "        lstm_weightih0_sigma_param = softplus(pyro.param(\"lstm_weightih0_sigma\", lstm_weightih0_sigma).to(device))\n",
        "        lstm_weightih0_prior = dist.Normal(loc=lstm_weightih0_mu_param, scale=lstm_weightih0_sigma_param).to_event(2)\n",
        "        lstm_biasih0_mu = torch.randn_like(net.lstm.bias_ih_l0)\n",
        "        lstm_biasih0_sigma = torch.randn_like(net.lstm.bias_ih_l0)\n",
        "        lstm_biasih0_mu_param = pyro.param(\"lstm_biasih0_mu\", lstm_biasih0_mu).to(device)\n",
        "        lstm_biasih0_sigma_param = softplus(pyro.param(\"lstm_biasih0_sigma\", lstm_biasih0_sigma).to(device))\n",
        "        lstm_biasih0_prior = dist.Normal(loc=lstm_biasih0_mu_param, scale=lstm_biasih0_sigma_param).to_event(1)\n",
        "\n",
        "        lstm_weightih1_mu = torch.randn_like(net.lstm.weight_ih_l1)\n",
        "        lstm_weightih1_sigma = torch.randn_like(net.lstm.weight_ih_l1)\n",
        "        lstm_weightih1_mu_param = pyro.param(\"lstm_weightih1_mu\", lstm_weightih1_mu).to(device)\n",
        "        lstm_weightih1_sigma_param = softplus(pyro.param(\"lstm_weightih1_sigma\", lstm_weightih1_sigma).to(device))\n",
        "        lstm_weightih1_prior = dist.Normal(loc=lstm_weightih1_mu_param, scale=lstm_weightih1_sigma_param).to_event(2)\n",
        "        lstm_biasih1_mu = torch.randn_like(net.lstm.bias_ih_l1)\n",
        "        lstm_biasih1_sigma = torch.randn_like(net.lstm.bias_ih_l1)\n",
        "        lstm_biasih1_mu_param = pyro.param(\"lstm_biasih1_mu\", lstm_biasih1_mu).to(device)\n",
        "        lstm_biasih1_sigma_param = softplus(pyro.param(\"lstm_biasih1_sigma\", lstm_biasih1_sigma).to(device))\n",
        "        lstm_biasih1_prior = dist.Normal(loc=lstm_biasih1_mu_param, scale=lstm_biasih1_sigma_param).to_event(1)\n",
        "\n",
        "        lstm_weighthh0_mu = torch.randn_like(net.lstm.weight_hh_l0)\n",
        "        lstm_weighthh0_sigma = torch.randn_like(net.lstm.weight_hh_l0)\n",
        "        lstm_weighthh0_mu_param = pyro.param(\"lstm_weighthh0_mu\", lstm_weighthh0_mu).to(device)\n",
        "        lstm_weighthh0_sigma_param = softplus(pyro.param(\"lstm_weighthh0_sigma\", lstm_weighthh0_sigma).to(device))\n",
        "        lstm_weighthh0_prior = dist.Normal(loc=lstm_weighthh0_mu_param, scale=lstm_weighthh0_sigma_param).to_event(2)\n",
        "        lstm_biashh0_mu = torch.randn_like(net.lstm.bias_hh_l0)\n",
        "        lstm_biashh0_sigma = torch.randn_like(net.lstm.bias_hh_l0)\n",
        "        lstm_biashh0_mu_param = pyro.param(\"lstm_biashh0_mu\", lstm_biashh0_mu).to(device)\n",
        "        lstm_biashh0_sigma_param = softplus(pyro.param(\"lstm_biashh0_sigma\", lstm_biashh0_sigma).to(device))\n",
        "        lstm_biashh0_prior = dist.Normal(loc=lstm_biashh0_mu_param, scale=lstm_biashh0_sigma_param).to_event(1)\n",
        "\n",
        "        lstm_weighthh1_mu = torch.randn_like(net.lstm.weight_hh_l1)\n",
        "        lstm_weighthh1_sigma = torch.randn_like(net.lstm.weight_hh_l1)\n",
        "        lstm_weighthh1_mu_param = pyro.param(\"lstm_weighthh1_mu\", lstm_weighthh1_mu).to(device)\n",
        "        lstm_weighthh1_sigma_param = softplus(pyro.param(\"lstm_weighthh1_sigma\", lstm_weighthh1_sigma).to(device))\n",
        "        lstm_weighthh1_prior = dist.Normal(loc=lstm_weighthh1_mu_param, scale=lstm_weighthh1_sigma_param).to_event(2)\n",
        "        lstm_biashh1_mu = torch.randn_like(net.lstm.bias_hh_l1)\n",
        "        lstm_biashh1_sigma = torch.randn_like(net.lstm.bias_hh_l1)\n",
        "        lstm_biashh1_mu_param = pyro.param(\"lstm_biashh1_mu\", lstm_biashh1_mu).to(device)\n",
        "        lstm_biashh1_sigma_param = softplus(pyro.param(\"lstm_biashh1_sigma\", lstm_biashh1_sigma).to(device))\n",
        "        lstm_biashh1_prior = dist.Normal(loc=lstm_biashh1_mu_param, scale=lstm_biashh1_sigma_param).to_event(1)\n",
        "\n",
        "        fc1w_mu = torch.randn_like(net.fc1.weight)\n",
        "        fc1w_sigma = torch.randn_like(net.fc1.weight)\n",
        "        fc1w_mu_param = pyro.param(\"fc1w_mu\", fc1w_mu).to(device)\n",
        "        fc1w_sigma_param = softplus(pyro.param(\"fc1w_sigma\", fc1w_sigma).to(device))\n",
        "        fc1w_prior = dist.Normal(loc=fc1w_mu_param, scale=fc1w_sigma_param).to_event(2)\n",
        "        fc1b_mu = torch.randn_like(net.fc1.bias)\n",
        "        fc1b_sigma = torch.randn_like(net.fc1.bias)\n",
        "        fc1b_mu_param = pyro.param(\"fc1b_mu\", fc1b_mu).to(device)\n",
        "        fc1b_sigma_param = softplus(pyro.param(\"fc1b_sigma\", fc1b_sigma).to(device))\n",
        "        fc1b_prior = dist.Normal(loc=fc1b_mu_param, scale=fc1b_sigma_param).to_event(1)\n",
        "\n",
        "        fc2w_mu = torch.randn_like(net.fc2.weight)\n",
        "        fc2w_sigma = torch.randn_like(net.fc2.weight)\n",
        "        fc2w_mu_param = pyro.param(\"fc2w_mu\", fc2w_mu).to(device)\n",
        "        fc2w_sigma_param = softplus(pyro.param(\"fc2w_sigma\", fc2w_sigma).to(device))\n",
        "        fc2w_prior = dist.Normal(loc=fc2w_mu_param, scale=fc2w_sigma_param).to_event(2)\n",
        "        fc2b_mu = torch.randn_like(net.fc2.bias)\n",
        "        fc2b_sigma = torch.randn_like(net.fc2.bias)\n",
        "        fc2b_mu_param = pyro.param(\"fc2b_mu\", fc2b_mu).to(device)\n",
        "        fc2b_sigma_param = softplus(pyro.param(\"fc2b_sigma\", fc2b_sigma).to(device))\n",
        "        fc2b_prior = dist.Normal(loc=fc2b_mu_param, scale=fc2b_sigma_param).to_event(1)\n",
        "\n",
        "        fc_static1w_mu = torch.randn_like(net.fc_static1.weight)\n",
        "        fc_static1w_sigma = torch.randn_like(net.fc_static1.weight)\n",
        "        fc_static1w_mu_param = pyro.param(\"fc_static1w_mu\", fc_static1w_mu).to(device)\n",
        "        fc_static1w_sigma_param = softplus(pyro.param(\"fc_static1w_sigma\", fc_static1w_sigma).to(device))\n",
        "        fc_static1w_prior = dist.Normal(loc=fc_static1w_mu_param, scale=fc_static1w_sigma_param).to_event(2)\n",
        "        fc_static1b_mu = torch.randn_like(net.fc_static1.bias)\n",
        "        fc_static1b_sigma = torch.randn_like(net.fc_static1.bias)\n",
        "        fc_static1b_mu_param = pyro.param(\"fc_static1b_mu\", fc_static1b_mu).to(device)\n",
        "        fc_static1b_sigma_param = softplus(pyro.param(\"fc_static1b_sigma\", fc_static1b_sigma).to(device))\n",
        "        fc_static1b_prior = dist.Normal(loc=fc_static1b_mu_param, scale=fc_static1b_sigma_param).to_event(1)\n",
        "\n",
        "        fc_static2w_mu = torch.randn_like(net.fc_static2.weight)\n",
        "        fc_static2w_sigma = torch.randn_like(net.fc_static2.weight)\n",
        "        fc_static2w_mu_param = pyro.param(\"fc_static2w_mu\", fc_static2w_mu).to(device)\n",
        "        fc_static2w_sigma_param = softplus(pyro.param(\"fc_static2w_sigma\", fc_static2w_sigma).to(device))\n",
        "        fc_static2w_prior = dist.Normal(loc=fc_static2w_mu_param, scale=fc_static2w_sigma_param).to_event(2)\n",
        "        fc_static2b_mu = torch.randn_like(net.fc_static2.bias)\n",
        "        fc_static2b_sigma = torch.randn_like(net.fc_static2.bias)\n",
        "        fc_static2b_mu_param = pyro.param(\"fc_static2b_mu\", fc_static2b_mu).to(device)\n",
        "        fc_static2b_sigma_param = softplus(pyro.param(\"fc_static2b_sigma\", fc_static2b_sigma).to(device))\n",
        "        fc_static2b_prior = dist.Normal(loc=fc_static2b_mu_param, scale=fc_static2b_sigma_param).to_event(1)\n",
        "\n",
        "\n",
        "        fc_final1w_mu = torch.randn_like(net.fc_final1.weight)\n",
        "        fc_final1w_sigma = torch.randn_like(net.fc_final1.weight)\n",
        "        fc_final1w_mu_param = pyro.param(\"fc_final1w_mu\", fc_final1w_mu).to(device)\n",
        "        fc_final1w_sigma_param = softplus(pyro.param(\"fc_final1w_sigma\", fc_final1w_sigma).to(device))\n",
        "        fc_final1w_prior = dist.Normal(loc=fc_final1w_mu_param, scale=fc_final1w_sigma_param).to_event(2)\n",
        "        fc_final1b_mu = torch.randn_like(net.fc_final1.bias)\n",
        "        fc_final1b_sigma = torch.randn_like(net.fc_final1.bias)\n",
        "        fc_final1b_mu_param = pyro.param(\"fc_final1b_mu\", fc_final1b_mu).to(device)\n",
        "        fc_final1b_sigma_param = softplus(pyro.param(\"fc_final1b_sigma\", fc_final1b_sigma).to(device))\n",
        "        fc_final1b_prior = dist.Normal(loc=fc_final1b_mu_param, scale=fc_final1b_sigma_param).to_event(1)\n",
        "\n",
        "        guide_priors = {'lstm.weight_ih_l0': lstm_weightih0_prior, 'lstm.bias_ih_l0': lstm_biasih0_prior,'lstm.weight_ih_l1': lstm_weightih1_prior, 'lstm.bias_ih_l1': lstm_biasih1_prior,\n",
        "                    'lstm.weight_hh_l0': lstm_weighthh0_prior, 'lstm.bias_hh_l0': lstm_biashh0_prior,'lstm.weight_hh_l1': lstm_weighthh1_prior, 'lstm.bias_hh_l1': lstm_biashh1_prior,\n",
        "                    #'lstm.weight_hr_l0': lstm_weighthr0_prior, 'lstm.bias_hr_l0': lstm_biashr0_prior,'lstm.weight_hr_l1': lstm_weighthr1_prior, 'lstm.bias_hr_l1': lstm_biashr1_prior,\n",
        "                    'fc1.weight': fc1w_prior, 'fc1.bias': fc1b_prior, 'fc2.weight': fc2w_prior, 'fc2.bias': fc2b_prior, 'fc_static1.weight': fc_static1w_prior, 'fc_static1.bias': fc_static1b_prior,'fc_static2.weight': fc_static2w_prior, 'fc_static2.bias': fc_static2b_prior,\n",
        "                    'fc_final1.weight': fc_final1w_prior, 'fc_final1.bias': fc_final1b_prior}\n",
        "        lifted_module = pyro.random_module(\"module\", net, guide_priors)  # Lift module parameters to random variables\n",
        "        return lifted_module().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tjWOIAdDc9Qa"
      },
      "outputs": [],
      "source": [
        "trainval_df = pd.read_pickle('/content/drive/MyDrive/Colab Notebooks/CognitiveAI/project/train.pkl').reset_index(drop=True)\n",
        "\n",
        "class_0 = trainval_df[trainval_df['label'] == 0]\n",
        "class_1 = trainval_df[trainval_df['label'] == 1]\n",
        "n_samples = len(class_1)\n",
        "class_0_downsampled = class_0.sample(n_samples)\n",
        "df_balanced = pd.concat([class_0_downsampled, class_1])\n",
        "train_df = df_balanced.reset_index(drop=True)\n",
        "\n",
        "N = len(train_df)\n",
        "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
        "val = train_df[:int(N*0.2)]\n",
        "train_df = train_df[int(N*0.2):]\n",
        "train_df.fillna(value=np.pi, inplace=True)\n",
        "val.fillna(value=np.pi, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJZDp7YMc9Qb",
        "outputId": "19fa2361-a8c4-41b1-be5d-4097c4c73966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28245, 35)\n",
            "(7061, 35)\n"
          ]
        }
      ],
      "source": [
        "print(train_df.shape)\n",
        "print(val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIgCphwGc9Qc",
        "outputId": "c0d9a01c-fbb6-4908-bc7a-6d8a588c0b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 8 dataloader workers every process\n",
            "using 28245 samples for training, 7061 samples for validation.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = SequenceDataset(train_df)\n",
        "valid_dataset = SequenceDataset(val)\n",
        "train_num = len(train_dataset)\n",
        "val_num = len(valid_dataset)\n",
        "batch_size=20\n",
        "nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
        "print('Using {} dataloader workers every process'.format(nw))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size=batch_size,\n",
        "                                               num_workers=nw, shuffle = True, drop_last=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                                                  batch_size=batch_size, shuffle=False,\n",
        "                                                  num_workers=nw, drop_last=True)\n",
        "\n",
        "print(\"using {} samples for training, {} samples for validation.\".format(train_num,\n",
        "                                                                           val_num))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZyTiXHcc9Qd",
        "outputId": "3ebb7ef4-8a00-405d-e13e-e7967cfb3360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 5])\n",
            "torch.Size([32])\n",
            "tensor(0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 10, 5])\n",
            "torch.Size([20, 32])\n",
            "torch.Size([20])\n"
          ]
        }
      ],
      "source": [
        "sample = train_dataset[0]\n",
        "print(sample[0].shape)\n",
        "print(sample[1].shape)\n",
        "print(sample[2])\n",
        "for x_dynamic, x_static, y in train_loader:\n",
        "    print(x_dynamic.shape)\n",
        "    print(x_static.shape)\n",
        "    print(y.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "gAqi979sc9Qd",
        "outputId": "a6a3ee86-20a8-4561-bb00-4e019a8587eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom pyro.infer import Predictive\\ndef predict(x_dynamic, x_static, model, guide, num_samples=100):\\n    predictive = Predictive(model, guide=guide, num_samples=num_samples, return_sites=[\"obs\", \"_RETURN\"])\\n    svi_samples = predictive(x_dynamic, x_static)\\n    #print(svi_samples)\\n    if \\'_RETURN\\' in svi_samples:\\n        predictions = torch.stack([svi_samples[\\'_RETURN\\'][i] for i in range(num_samples)])\\n    else:\\n        predictions = torch.stack([svi_samples[\\'obs\\'][i].float() for i in range(num_samples)])\\n    predicted_probabilities = torch.mean(predictions, dim=0)\\n    predicted_labels = predicted_probabilities.argmax(dim=-1)\\n    return predicted_labels'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "num_samples = 5\n",
        "\n",
        "def predict(x_dynamic, x_static):\n",
        "    sampled_models = [guide(None, None) for _ in range(num_samples)]\n",
        "    yhats = [model(x_dynamic, x_static).data for model in sampled_models]\n",
        "    mean = torch.mean(torch.stack(yhats), 0)\n",
        "    #print(mean.numpy())\n",
        "    return np.argmax(mean.cpu().numpy(), axis=1)#(mean > 0.5).float().reshape(-1)'''\n",
        "'''\n",
        "from pyro.infer import Predictive\n",
        "def predict(x_dynamic, x_static, model, guide, num_samples=100):\n",
        "    predictive = Predictive(model, guide=guide, num_samples=num_samples, return_sites=[\"obs\", \"_RETURN\"])\n",
        "    svi_samples = predictive(x_dynamic, x_static)\n",
        "    #print(svi_samples)\n",
        "    if '_RETURN' in svi_samples:\n",
        "        predictions = torch.stack([svi_samples['_RETURN'][i] for i in range(num_samples)])\n",
        "    else:\n",
        "        predictions = torch.stack([svi_samples['obs'][i].float() for i in range(num_samples)])\n",
        "    predicted_probabilities = torch.mean(predictions, dim=0)\n",
        "    predicted_labels = predicted_probabilities.argmax(dim=-1)\n",
        "    return predicted_labels'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "1xBRfMoVc9Qe"
      },
      "outputs": [],
      "source": [
        "def train(model, guide, train_loader, valid_loader, num_epochs=30):\n",
        "\n",
        "    optim = Adam({\"lr\":1e-3})\n",
        "    svi = SVI(model, guide, optim, loss=Trace_ELBO())\n",
        "    train_loss_list = []\n",
        "    train_acc_list = []\n",
        "    valid_loss_list = []\n",
        "    valid_acc_list = []\n",
        "    #model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total_train = 0\n",
        "        for x_dynamic, x_static, y in train_loader:\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                x_dynamic = x_dynamic.cuda()\n",
        "                x_static = x_static.cuda()\n",
        "                y = y.cuda()\n",
        "            #print(x_dynamic.shape)\n",
        "            loss = svi.step(x_dynamic, x_static, y)\n",
        "            total_loss += loss\n",
        "\n",
        "            with torch.no_grad():\n",
        "                #lifted_module = model.guide(x_dynamic, x_static, y)\n",
        "                pred_label = predict(x_dynamic, x_static)\n",
        "                #print(f\"the prediction prob is:{pred.reshape(-1)}\")\n",
        "                #pred = torch.sigmoid(pred)\n",
        "            #pred_label = (pred > 0.5).float()\n",
        "            #print(type(pred_label))\n",
        "            correct += (pred_label.reshape(-1) == y.cpu().numpy().reshape(-1)).astype(int).sum().item()\n",
        "            total_train += y.shape[0]\n",
        "            #print(pred_label.reshape(-1))\n",
        "            #print(y.shape[0])\n",
        "        epoch_loss = total_loss / total_train\n",
        "        epoch_accuracy = correct / total_train\n",
        "        train_acc_list.append(epoch_accuracy)\n",
        "        print(f\"Epoch {epoch+1}, Train Loss: {epoch_loss}, Train Accuracy: {epoch_accuracy}\")\n",
        "        train_loss_list.append(epoch_loss)\n",
        "\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for x_dynamic, x_static, y_val in valid_loader:\n",
        "            #model.eval()\n",
        "            if torch.cuda.is_available():\n",
        "                x_dynamic = x_dynamic.cuda()\n",
        "                x_static = x_static.cuda()\n",
        "                y_val = y_val.cuda()\n",
        "            with torch.no_grad():\n",
        "                loss = svi.evaluate_loss(x_dynamic, x_static, y_val)\n",
        "                total_loss += loss\n",
        "                #lifted_module = model.guide(x_dynamic, x_static, y)\n",
        "                pred_label = predict(x_dynamic, x_static)\n",
        "                #print(pred)\n",
        "                #pred = torch.sigmoid(pred)\n",
        "                #pred_label = (pred > 0.5).float()\n",
        "                total += y_val.shape[0]\n",
        "                correct += (pred_label.reshape(-1) == y_val.cpu().numpy().reshape(-1)).astype(int).sum().item()\n",
        "\n",
        "            epoch_loss = total_loss / total\n",
        "        epoch_accuracy = correct / total\n",
        "        valid_acc_list.append(epoch_accuracy)\n",
        "        print(f\"Epoch {epoch+1}, Validation Loss: {epoch_loss}, Validation Accuracy: {epoch_accuracy}\")\n",
        "        valid_loss_list.append(epoch_loss)\n",
        "    return train_loss_list, train_acc_list, valid_loss_list, valid_acc_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT7cO-Pmc9Qe",
        "outputId": "85a95603-ab02-4493-9748-ed2d739d47a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1412\n"
          ]
        }
      ],
      "source": [
        "print(len(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHrBNSxXc9Qf",
        "outputId": "7879e787-8cfa-4ccd-91e5-b04fc97a1747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/pyro/primitives.py:526: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:836: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  if param.grad is not None:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 2814.7792652415033, Train Accuracy: 0.5489376770538243\n",
            "Epoch 1, Validation Loss: 2737.365887260977, Validation Accuracy: 0.5624645892351274\n"
          ]
        }
      ],
      "source": [
        "#net = BayesianLSTM(dyn_channels=5, stat_channels=32, hidden_size=50, num_layers=2)\n",
        "train_loss_list, train_acc_list, valid_loss_list, valid_acc_list = train(model, guide, train_loader, valid_loader, num_epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRedJOrUc9Qf"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(train_loss_list, label=\"train_loss\")\n",
        "plt.plot(valid_loss_list, label=\"valid_loss\")\n",
        "plt.legend()\n",
        "plt.title(f\"Loss curve\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train_acc_list, label=\"train_acc\")\n",
        "plt.plot(valid_acc_list, label=\"valid_acc\")\n",
        "plt.legend()\n",
        "plt.title(f\"Accuracy curve\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMeX_cYUc9Qg"
      },
      "outputs": [],
      "source": [
        "batch_size=20\n",
        "test_df = pd.read_pickle('/content/drive/MyDrive/Colab Notebooks/CognitiveAI/project/test.pkl').reset_index(drop=True)\n",
        "\n",
        "class_0 = test_df[test_df['label'] == 0]\n",
        "class_1 = test_df[test_df['label'] == 1]\n",
        "n_samples = len(class_1)\n",
        "class_0_downsampled = class_0.sample(n_samples)\n",
        "df_balanced = pd.concat([class_0_downsampled, class_1])\n",
        "test_df = df_balanced.reset_index(drop=True)\n",
        "\n",
        "N = len(test_df)\n",
        "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
        "test_df.fillna(value=np.pi, inplace=True)\n",
        "test_dataset = SequenceDataset(test_df)\n",
        "test_num = len(test_dataset)\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                               batch_size=batch_size,\n",
        "                                               num_workers=nw, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ei4-fx6vc9Qh"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "y_true=[]\n",
        "y_pred=[]\n",
        "for x_dynamic, x_static, y in test_loader:\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                x_dynamic = x_dynamic.cuda()\n",
        "                x_static = x_static.cuda()\n",
        "                y = y.cuda()\n",
        "            y = y.float()\n",
        "\n",
        "            lifted_module = model.guide(x_dynamic, x_static, y)\n",
        "            pred_label = predict(x_dynamic, x_static)\n",
        "            total += y.shape[0]\n",
        "            correct += (pred_label.reshape(-1) == y.numpy().reshape(-1)).astype(int).sum().item()\n",
        "            y_true.append(y.reshape(-1))\n",
        "            y_pred.append(pred_label.reshape(-1))\n",
        "\n",
        "print(f\"the test accuracy is {correct/total}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiDCpYozc9Qh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import seaborn as sns\n",
        "y_true = np.concatenate(y_true)\n",
        "y_pred = np.concatenate(y_pred)\n",
        "CM = confusion_matrix(y_true, y_pred)\n",
        "#auc_score = roc_auc_score(y_true, y_prob_list, multi_class='ovr')\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(CM, annot=True, fmt=\"d\", cmap='Blues')#, xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlS2bHc7c9Qi"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'result/blstm.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYzkAyhsc9Qi"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name} has values: \\n{param.data}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}